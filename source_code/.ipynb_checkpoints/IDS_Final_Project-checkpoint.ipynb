{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "sentiment1 =  pd.read_csv('sentiment.csv')\n",
    "sentiment = ps.sqldf(\"\"\"select \n",
    "                        business_id,\n",
    "                        round(sentimental_rating,0) as sentimental_rating\n",
    "                        from sentiment1\"\"\", locals())\n",
    "sentiment.describe()\n",
    "sentiment.head()\n",
    "\n",
    "business = pd.read_csv('business.csv')\n",
    "business.rename(columns = {'stars':'business_stars'}, inplace = True)\n",
    "business.head()\n",
    "business.describe()\n",
    "business.columns\n",
    "\n",
    "####### REVIEW\n",
    "review = pd.read_csv('review.csv', iterator=True, chunksize=500)\n",
    "review = pd.concat(review, ignore_index =True)\n",
    "review.describe()\n",
    "review.columns\n",
    "review.head()\n",
    "business.head()\n",
    "\n",
    "business_eateries = business[(business['categories'].str.contains(pat = 'Restaurants',na=False)) |\n",
    "                                       (business['categories'].str.contains(pat = 'Lounges',na=False)) |\n",
    "                                        (business['categories'].str.contains(pat = 'Nightlife',na=False)) |\n",
    "                                        (business['categories'].str.contains(pat = 'Bars',na=False)) |\n",
    "                                        (business['categories'].str.contains(pat = 'Food',na=False)) |\n",
    "                                        (business['categories'].str.contains(pat = 'Coffee&Tea',na=False))|\n",
    "                                        (business['categories'].str.contains(pat = 'Bakeries',na=False))|\n",
    "                                        (business['categories'].str.contains(pat = 'Pubs',na=False))|\n",
    "                                        (business['categories'].str.contains(pat = 'Pizza',na=False))]\n",
    "business_eateries.describe()\n",
    "\n",
    "business_eateries.columns\n",
    "business_eateries.head()\n",
    "\n",
    "cols = business_eateries.columns\n",
    "cols = cols.map(lambda x: x.replace('.', '_'))\n",
    "business_eateries.columns = cols\n",
    "# write business_eateries csv\n",
    "business_eateries.to_csv('Businesses_Eateries.csv')\n",
    "business_eateries.head()\n",
    "\n",
    "business_eateries_sentiment = pd.merge(business_eateries, sentiment, on = 'business_id')\n",
    "business_eateries_sentiment.to_csv('Business_Eateries_Sentiment.csv')\n",
    "\n",
    "business_review = pd.merge(business, review, on = 'business_id')\n",
    "review_grouped = business_review.groupby(['city' , 'business_id'], as_index=False).mean()\n",
    "data = review_grouped[['business_id','stars']]\n",
    "review_eateries = data.apply(lambda x: x)\n",
    "review_eateries.rename(columns={'stars': 'review_avg_stars'}, inplace=True)\n",
    "review_eateries.head()\n",
    "\n",
    "business_reviews_eateries = pd.merge(business_eateries, review_eateries, on = 'business_id')\n",
    "business_reviews_eateries.head()\n",
    "print(business_reviews_eateries.columns)\n",
    "\n",
    "business_relevant_review_eateries = business_reviews_eateries[['business_id','latitude', 'longitude','review_count'\n",
    "                  ,'business_stars','review_avg_stars','attributes_RestaurantsPriceRange2','attributes_BusinessAcceptsCreditCards','attributes_RestaurantsTakeOut','attributes_RestaurantsDelivery',\n",
    "                        'attributes_WheelchairAccessible','attributes_GoodForMeal_breakfast','attributes_GoodForMeal_latenight','attributes_GoodForMeal_dessert','attributes_GoodForMeal_lunch',\n",
    "                        'attributes_GoodForMeal_brunch','attributes_RestaurantsReservations','attributes_BusinessParking_validated','attributes_BusinessParking_valet','attributes_BusinessParking_lot','attributes_BusinessParking_garage',\n",
    "                        'attributes_BusinessParking_street','attributes_BikeParking','state','city','name','attributes_GoodForKids','attributes_RestaurantsGoodForGroups','attributes_Ambience_trendy','attributes_Ambience_casual','attributes_Ambience_classy','attributes_Ambience_touristy','attributes_Ambience_intimate'\n",
    "                        ,'attributes_Ambience_hipster']]\n",
    "\n",
    "\n",
    "business_relevant_review_eateries.head()\n",
    "\n",
    "business_relevant_review_eateries_sentiment = pd.merge(business_relevant_review_eateries, sentiment, on = 'business_id')\n",
    "business_relevant_review_eateries_sentiment.to_csv('Model_Input.csv')\n",
    "business_relevant_review_eateries_sentiment.head()\n",
    "\n",
    "print(\"Data Cleaning Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshit Vijayvargia\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "attributes = ['attributes_RestaurantsPriceRange2',\n",
    "              'attributes_BusinessAcceptsCreditCards',\n",
    "              'attributes_RestaurantsTakeOut',\n",
    "              'attributes_RestaurantsDelivery',\n",
    "              'attributes_WheelchairAccessible',\n",
    "              'attributes_GoodForMeal_breakfast',\n",
    "              'attributes_GoodForMeal_latenight',\n",
    "              'attributes_GoodForMeal_dessert',\n",
    "              'attributes_GoodForMeal_lunch',\n",
    "              'attributes_GoodForMeal_brunch',\n",
    "              'attributes_RestaurantsReservations',\n",
    "              'attributes_BusinessParking_validated',\n",
    "              'attributes_BusinessParking_valet',\n",
    "              'attributes_BusinessParking_lot',\n",
    "              'attributes_BusinessParking_garage', \n",
    "              'attributes_BusinessParking_street',\n",
    "              'attributes_BikeParking',\n",
    "              'attributes_GoodForKids',\n",
    "              'attributes_RestaurantsGoodForGroups',\n",
    "              'attributes_Ambience_trendy',\n",
    "              'attributes_Ambience_casual',\n",
    "              'attributes_Ambience_classy',\n",
    "              'attributes_Ambience_touristy',\n",
    "              'attributes_Ambience_intimate',\n",
    "              'attributes_Ambience_hipster',\n",
    "              'latitude',\n",
    "              'longitude',\n",
    "              'business_stars', \n",
    "              'review_count', \n",
    "              'sentimental_rating',\n",
    "              'review_avg_stars']\n",
    "\n",
    "print('---- Reading Model_input.csv -------- ')\n",
    "\n",
    "model_input_dict = defaultdict(dict)           \n",
    "\n",
    "with open('Model_Input.csv') as csvfile:\n",
    "    \n",
    "    reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    for row in reader:\n",
    "        for attribute in attributes[:25]:\n",
    "            if row[attribute] == 'TRUE':\n",
    "                row[attribute] = 1\n",
    "            elif row[attribute] == 'FALSE':\n",
    "                row[attribute] = 0\n",
    "            else:\n",
    "                row[attribute] = 0\n",
    "        \n",
    "        model_input_dict[row['city']].update({ \n",
    "                                            row['business_id'] : \n",
    "                                            [ \n",
    "                                                int(row[attributes[0]]),\n",
    "                                                int(row[attributes[1]]), \n",
    "                                                int(row[attributes[2]]), \n",
    "                                                int(row[attributes[3]]), \n",
    "                                                int(row[attributes[4]]), \n",
    "                                                int(row[attributes[5]]), \n",
    "                                                int(row[attributes[6]]), \n",
    "                                                int(row[attributes[7]]), \n",
    "                                                int(row[attributes[8]]), \n",
    "                                                int(row[attributes[9]]), \n",
    "                                                int(row[attributes[10]]), \n",
    "                                                int(row[attributes[11]]),\n",
    "                                                int(row[attributes[12]]),\n",
    "                                                int(row[attributes[13]]),\n",
    "                                                int(row[attributes[14]]),\n",
    "                                                int(row[attributes[15]]),\n",
    "                                                int(row[attributes[16]]),\n",
    "                                                int(row[attributes[17]]),\n",
    "                                                int(row[attributes[18]]),\n",
    "                                                int(row[attributes[19]]),\n",
    "                                                int(row[attributes[20]]),\n",
    "                                                int(row[attributes[21]]),\n",
    "                                                int(row[attributes[22]]),\n",
    "                                                int(row[attributes[23]]),\n",
    "                                                int(row[attributes[24]]),\n",
    "                                                float(row[attributes[25]]),\n",
    "                                                float(row[attributes[26]]),\n",
    "                                                float(row[attributes[27]]),\n",
    "                                                int(row[attributes[28]]),\n",
    "                                                float(row[attributes[29]]),\n",
    "                                                int(numpy.round(float(row[attributes[30]]))),\n",
    "                                            ]\n",
    "                                            })\n",
    "\n",
    "\n",
    "print('------Model Making Started-------')\n",
    "\n",
    "results = defaultdict(list)\n",
    "cities_models = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 30)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f813a31394a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m#print(labels_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#print(labels_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mfeatures_train_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mfeatures_test_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Harshit Vijayvargia\\Anaconda2\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Harshit Vijayvargia\\Anaconda2\\lib\\site-packages\\sklearn\\preprocessing\\data.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Harshit Vijayvargia\\Anaconda2\\lib\\site-packages\\sklearn\\preprocessing\\data.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Harshit Vijayvargia\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    414\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 416\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 30)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "######################### Run this cell for RandomForest###############################################\n",
    "for city, business_dict in model_input_dict.items():\n",
    "    final_features = []\n",
    "    final_labels = []\n",
    "    #print(city)\n",
    "    #print(business_dict)\n",
    "    for business, features_list in business_dict.items():\n",
    "        #print(business)\n",
    "        #print(features_list)\n",
    "        final_features.append(features_list[:-1]) #everything except the last item \n",
    "        final_labels.append(features_list[-1]) #last label\n",
    "   \n",
    "    \n",
    "        #print(final_features)\n",
    "        #print(final_labels)\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(numpy.array(final_features), numpy.array(final_labels), \n",
    "                                                       test_size=0.2, random_state = 42)\n",
    "        #print(features_train)\n",
    "        #print(features_test)\n",
    "        #print(labels_train)\n",
    "        #print(labels_test)\n",
    "                                                                                \n",
    "        #labels_train = column_or_1d(labels_train, warn=False)\n",
    "        #labels_test = column_or_1d(labels_test, warn=False)          \n",
    "        #print(labels_train)\n",
    "        #print(labels_test)\n",
    "        features_train_transformed = preprocessing.StandardScaler().fit_transform(features_train)\n",
    "        features_test_transformed = preprocessing.StandardScaler().fit_transform(features_test)\n",
    "    \n",
    "        #clf = SVC(C=1).fit(features_train_transformed, labels_train)\n",
    "        #train_accuracy = clf.score(features_train_transformed, labels_train)\n",
    "        #test_accuracy = clf.score(features_test_transformed, labels_test)\n",
    "        #print(train_accuracy)\n",
    "        #print(test_accuracy)\n",
    "    \n",
    "        clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "              min_samples_split=2, random_state=0)\n",
    "        clf = clf.fit(features_train_transformed, labels_train)\n",
    "        train_accuracy = clf.score(features_train_transformed, labels_train)\n",
    "        test_accuracy = clf.score(features_test_transformed, labels_test)\n",
    "\n",
    "        if train_accuracy >=0.65 and test_accuracy>=0.60:\n",
    "            cities_models[city] = clf\n",
    "            results[city].append(features_train.shape)\n",
    "            results[city].append(features_test.shape)\n",
    "            results[city].append(train_accuracy)\n",
    "            results[city].append(test_accuracy)\n",
    "        \n",
    "print('------Write accuracy in file-------')\n",
    "final_results = []\n",
    "for u, r in results.items():\n",
    "    train_rows = r[0][0]\n",
    "    test_rows = r[1][0]\n",
    "    final_results.append([u, train_rows, test_rows, r[2], r[3]])\n",
    "    \n",
    "resultFile = open('Cities_Model_Fit_Accuracies_RandomForest.csv','w')\n",
    "wr = csv.writer(resultFile, delimiter=',', lineterminator='\\n' )\n",
    "wr.writerow(['city', 'features_train_rows' , 'features_test_rows', 'train_accuracy', 'test_accuracy'])\n",
    "wr.writerows(final_results)\n",
    "resultFile.close()\n",
    "\n",
    "# visualize train and test accuracies\n",
    "sentiment = pd.read_csv('Cities_Model_Fit_Accuracies_RandomForest.csv')\n",
    "sentiment = sentiment.head(5)\n",
    "sentiment['train_accuracy'] = sentiment['train_accuracy'].astype(float)\n",
    "sentiment['test_accuracy'] = sentiment['test_accuracy'].astype(float)\n",
    "\n",
    "fig,ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "x = sentiment.city\n",
    "xn = range(len(x))\n",
    "plt.xticks(xn, sentiment['city'])\n",
    "ax1.plot(xn, sentiment['train_accuracy'], 'g-')\n",
    "ax2.plot(xn, sentiment['test_accuracy'], 'r-')\n",
    "ax1.set_xlabel('City')\n",
    "ax1.set_ylabel('Train Accuracy', color='g')\n",
    "ax2.set_ylabel('Test Accuracy', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################Visualize train and test accuracies with various SVM kernels###################\n",
    "classifiers = [\n",
    "   SVC(kernel=\"rbf\", C=1),\n",
    "   SVC(kernel=\"rbf\", C=2),,\n",
    "   SVC(kernel=\"linear\", C=0.025),\n",
    "   SVC(kernel=\"linear\", C=0.5),\n",
    "   SVC(kernel=\"linear\", C=1,\n",
    "   SVC(kernel=\"linear\", C=2))]\n",
    "\n",
    "names = [\"SVM-C1-RBF\", \"SVM-C2-RBF\", \"SVM-C0.025-linear\", \"SVM-C0.5-linear\",\n",
    "        \"SVM-C1-linear\", \"SVM-C2-linear\"]\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    tot_train = 0\n",
    "    tot_test = 0\n",
    "    count = 0\n",
    "    for city, business_dict in model_input_dict.items():\n",
    "        count = count + 1\n",
    "        final_features = []\n",
    "        final_labels = []\n",
    "        #print(city)\n",
    "        #print(business_dict)\n",
    "        for business, features_list in business_dict.items():\n",
    "            #print(business)\n",
    "            #print(features_list)\n",
    "            final_features.append(features_list[:-1]) #everything except the last item \n",
    "            final_labels.append(features_list[-1]) #last label\n",
    "   \n",
    "    \n",
    "        #print(final_features)\n",
    "        #print(final_labels)\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(numpy.array(final_features), numpy.array(final_labels), \n",
    "                                                       test_size=0.2, random_state = 42)\n",
    "        #print(features_train)\n",
    "        #print(features_test)\n",
    "        #print(labels_train)\n",
    "        #print(labels_test)\n",
    "                                                                                \n",
    "        #labels_train = column_or_1d(labels_train, warn=False)\n",
    "        #labels_test = column_or_1d(labels_test, warn=False)          \n",
    "        #print(labels_train)\n",
    "        #print(labels_test)\n",
    "        features_train_transformed = preprocessing.StandardScaler().fit_transform(features_train)\n",
    "        features_test_transformed = preprocessing.StandardScaler().fit_transform(features_test)\n",
    "    \n",
    "        clf = SVC(C=1).fit(features_train_transformed, labels_train)\n",
    "        train_accuracy = clf.score(features_train_transformed, labels_train)\n",
    "        test_accuracy = clf.score(features_test_transformed, labels_test)\n",
    "        #print(train_accuracy)\n",
    "        #print(test_accuracy)\n",
    "        \n",
    "        tot_train = tot_train + train_accuracy\n",
    "        tot_test = tot_test + train_test\n",
    "    \n",
    "    train_list = train_list.append(tot_train*100/count)\n",
    "    test_list = train_list.append(tot_train*100/count)\n",
    "\n",
    "list1 = names\n",
    "list2 = train_list\n",
    "list3 = test_list\n",
    "\n",
    "#visualize train and test accuracies for different svm kernels\n",
    "fig,ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "x = list1\n",
    "xn = range(len(x))\n",
    "plt.xticks(xn, list1)\n",
    "ax1.plot(xn, list2, 'g-')\n",
    "ax2.plot(xn, list3, 'r-')\n",
    "\n",
    "ax1.set_xlabel('Classifiers')\n",
    "ax1.set_ylabel('Train Accuracy', color='g')\n",
    "ax2.set_ylabel('Test Accuracy', color='r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################Run this cell for SVM############################################\n",
    "for city, business_dict in model_input_dict.items():\n",
    "    final_features = []\n",
    "    final_labels = []\n",
    "    #print(city)\n",
    "    #print(business_dict)\n",
    "    for business, features_list in business_dict.items():\n",
    "        #print(business)\n",
    "        #print(features_list)\n",
    "        final_features.append(features_list[:-1]) #everything except the last item \n",
    "        final_labels.append(features_list[-1]) #last label\n",
    "   \n",
    "    \n",
    "    #print(final_features)\n",
    "    #print(final_labels)\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(numpy.array(final_features), numpy.array(final_labels), \n",
    "                                                       test_size=0.2, random_state = 42)\n",
    "    #print(features_train)\n",
    "    #print(features_test)\n",
    "    #print(labels_train)\n",
    "    #print(labels_test)\n",
    "                                                                                \n",
    "    #labels_train = column_or_1d(labels_train, warn=False)\n",
    "    #labels_test = column_or_1d(labels_test, warn=False)          \n",
    "    #print(labels_train)\n",
    "    #print(labels_test)\n",
    "    features_train_transformed = preprocessing.StandardScaler().fit_transform(features_train)\n",
    "    features_test_transformed = preprocessing.StandardScaler().fit_transform(features_test)\n",
    "    \n",
    "    clf = SVC(C=1).fit(features_train_transformed, labels_train)\n",
    "    train_accuracy = clf.score(features_train_transformed, labels_train)\n",
    "    test_accuracy = clf.score(features_test_transformed, labels_test)\n",
    "    #print(train_accuracy)\n",
    "    #print(test_accuracy)\n",
    "    \n",
    "\n",
    "    if train_accuracy >=0.65 and test_accuracy>=0.60:\n",
    "        cities_models[city] = clf\n",
    "        results[city].append(features_train.shape)\n",
    "        results[city].append(features_test.shape)\n",
    "        results[city].append(train_accuracy)\n",
    "        results[city].append(test_accuracy)\n",
    "        \n",
    "print('------Write accuracy in file-------')\n",
    "final_results = []\n",
    "for u, r in results.items():\n",
    "    train_rows = r[0][0]\n",
    "    test_rows = r[1][0]\n",
    "    final_results.append([u, train_rows, test_rows, r[2], r[3]])\n",
    "    \n",
    "resultFile = open('Cities_Model_Fit_Accuracies_SVM.csv','w')\n",
    "wr = csv.writer(resultFile, delimiter=',', lineterminator='\\n' )\n",
    "wr.writerow(['city', 'features_train_rows' , 'features_test_rows', 'train_accuracy', 'test_accuracy'])\n",
    "wr.writerows(final_results)\n",
    "resultFile.close()\n",
    "\n",
    "# visualize train and test accuracies\n",
    "sentiment = pd.read_csv('Cities_Model_Fit_Accuracies_SVM.csv')\n",
    "sentiment = sentiment.head(5)\n",
    "sentiment['train_accuracy'] = sentiment['train_accuracy'].astype(float)\n",
    "sentiment['test_accuracy'] = sentiment['test_accuracy'].astype(float)\n",
    "fig,ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "x = sentiment.city\n",
    "xn = range(len(x))\n",
    "plt.xticks(xn, sentiment['city'])\n",
    "ax1.plot(xn, sentiment['train_accuracy'], 'g-')\n",
    "ax2.plot(xn, sentiment['test_accuracy'], 'r-')\n",
    "ax1.set_xlabel('City')\n",
    "ax1.set_ylabel('Train Accuracy', color='g')\n",
    "ax2.set_ylabel('Test Accuracy', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################Build New Businesses for cities and do Prediction###########################\n",
    "print(\"-----Generate list of Old Businesses for Cities -------\")\n",
    "all_cities_old_businesses = defaultdict(set)\n",
    "for city, business_list in model_input_dict.items():\n",
    "    if city in results.keys():\n",
    "        for b in business_list.keys():\n",
    "            all_cities_old_businesses[city].add(b)\n",
    "            \n",
    "print(\"----- Generate set of all businesses -------\")\n",
    "all_business = []\n",
    "all_business_features = defaultdict(list)\n",
    "with open('Business_Eateries_Sentiment.csv') as businessfile:\n",
    "    b_reader = csv.DictReader(businessfile)\n",
    "    for row in b_reader:\n",
    "        business_id = row['business_id']\n",
    "        all_business.append(business_id)  \n",
    "       \n",
    "    for attribute in attributes[:25]:\n",
    "        if row[attribute] == 'TRUE':\n",
    "            row[attribute] = 1\n",
    "        elif row[attribute] == 'FALSE':\n",
    "            row[attribute] = 0\n",
    "        else:\n",
    "            row[attribute] = 0\n",
    "        \n",
    "    all_business_features[row['city']].update({ \n",
    "                                            row['business_id'] : \n",
    "                                            [ \n",
    "                                                int(row[attributes[0]]),\n",
    "                                                int(row[attributes[1]]), \n",
    "                                                int(row[attributes[2]]), \n",
    "                                                int(row[attributes[3]]), \n",
    "                                                int(row[attributes[4]]), \n",
    "                                                int(row[attributes[5]]), \n",
    "                                                int(row[attributes[6]]), \n",
    "                                                int(row[attributes[7]]), \n",
    "                                                int(row[attributes[8]]), \n",
    "                                                int(row[attributes[9]]), \n",
    "                                                int(row[attributes[10]]), \n",
    "                                                int(row[attributes[11]]),\n",
    "                                                int(row[attributes[12]]),\n",
    "                                                int(row[attributes[13]]),\n",
    "                                                int(row[attributes[14]]),\n",
    "                                                int(row[attributes[15]]),\n",
    "                                                int(row[attributes[16]]),\n",
    "                                                int(row[attributes[17]]),\n",
    "                                                int(row[attributes[18]]),\n",
    "                                                int(row[attributes[19]]),\n",
    "                                                int(row[attributes[20]]),\n",
    "                                                int(row[attributes[21]]),\n",
    "                                                int(row[attributes[22]]),\n",
    "                                                int(row[attributes[23]]),\n",
    "                                                int(row[attributes[24]]),\n",
    "                                                float(row[attributes[25]]),\n",
    "                                                float(row[attributes[26]]),\n",
    "                                                float(row[attributes[27]]),\n",
    "                                                int(row[attributes[28]]),\n",
    "                                                float(row[attributes[29]])\n",
    "                                            ]\n",
    "                                            })\n",
    "\n",
    "print(\"------- Diff the businesses for cities --------- \")                                                \n",
    "all_business = set(all_business)\n",
    "all_cities_new_businesses = defaultdict(list)\n",
    "\n",
    "for city, business_set in all_cities_old_businesses.items():\n",
    "    diff_business = all_business.symmetric_difference(business_set)\n",
    "    all_cities_new_businesses[city] = list(diff_business)\n",
    "    \n",
    "print(\"------Generating new businesses for users --------\")\n",
    "all_cities_new_businesses_features = defaultdict(dict)\n",
    "final_results =[]\n",
    "for city, business_list in all_cities_new_businesses.items():\n",
    "    for business in business_list:\n",
    "        final_results.append([city , business] +  all_business_features[b] )\n",
    "        all_cities_new_businesses_features[city].update({ business : all_business_features[business]})\n",
    "        \n",
    "test_city = list(all_cities_new_businesses_features.keys())[0]\n",
    "print(all_cities_new_businesses_features[test_city])\n",
    "       \n",
    "# write results to a csv\n",
    "resultFile = open(\"Model_New_Businesses_Ouput.csv\",'w')\n",
    "wr = csv.writer(resultFile, delimiter=',', lineterminator='\\n' )\n",
    "wr.writerow(['city', 'business_id', 'attributes_RestaurantsPriceRange2',\n",
    "              'attributes_BusinessAcceptsCreditCards',\n",
    "              'attributes_RestaurantsTakeOut',\n",
    "              'attributes_RestaurantsDelivery',\n",
    "              'attributes_WheelchairAccessible',\n",
    "              'attributes_GoodForMeal_breakfast',\n",
    "              'attributes_GoodForMeal_latenight',\n",
    "              'attributes_GoodForMeal_dessert',\n",
    "              'attributes_GoodForMeal_lunch',\n",
    "              'attributes_GoodForMeal_brunch',\n",
    "              'attributes_RestaurantsReservations',\n",
    "              'attributes_BusinessParking_validated',\n",
    "              'attributes_BusinessParking_valet',\n",
    "              'attributes_BusinessParking_lot',\n",
    "              'attributes_BusinessParking_garage', \n",
    "              'attributes_BusinessParking_street',\n",
    "              'attributes_BikeParking',\n",
    "              'attributes_GoodForKids',\n",
    "              'attributes_RestaurantsGoodForGroups',\n",
    "              'attributes_Ambience_trendy',\n",
    "              'attributes_Ambience_casual',\n",
    "              'attributes_Ambience_classy',\n",
    "              'attributes_Ambience_touristy',\n",
    "              'attributes_Ambience_intimate',\n",
    "              'attributes_Ambience_hipster',\n",
    "              'latitude',\n",
    "              'longitude',\n",
    "              'business_stars', \n",
    "              'review_count', \n",
    "              'sentimental_rating'])\n",
    "wr.writerows(final_results)\n",
    "resultFile.close()\n",
    "\n",
    "print(\"----- Predicting new businesses and Writing --------\")\n",
    "resultFile = open(\"Model_Prediction_Ouput.csv\",'w')\n",
    "wr = csv.writer(resultFile, delimiter=',', lineterminator='\\n' )\n",
    "wr.writerow(['city', 'business_id' , 'prediction'])\n",
    "all_cities_new_businesses_predictions = defaultdict(dict)\n",
    "for city, business_list in all_cities_new_businesses_features.items():\n",
    "    for new_business, new_business_features in business_list.items():\n",
    "        predicted_label = cities_models[city].predict([new_business_features]) \n",
    "        wr.writerow([city, new_business, predicted_label[0]])\n",
    "        all_cities_new_businesses_predictions[city] = { new_business : predicted_label[0] }\n",
    "\n",
    "resultFile.close()       \n",
    "print(\"Prediction Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################### analyze the predicted results for 5 cities#######################################\n",
    "count = 0\n",
    "cities = []\n",
    "actual_avg_stars = []\n",
    "pred_avg_stars = []\n",
    "\n",
    "for city, business_list in all_cities_new_businesses_features.items():\n",
    "    count = count + 1\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    #print(city)\n",
    "    #print(business_dict)\n",
    "    for new_business, new_business_features in business_list.items():\n",
    "        #print(business)\n",
    "        #print(features_list)\n",
    "        true_labels.append(model_input_dict[city][new_business][-1])        \n",
    "        predicted_labels.append(all_cities_new_businesses_predictions[city][new_business])\n",
    "    \n",
    "    predicted_labels = numpy.array(predicted_labels)\n",
    "    true_labels = numpy.array(true_labels)\n",
    "    \n",
    "    actual_avg_stars.append(true_labels.mean())\n",
    "    pred_avg_stars.append(predicted_labels.mean())\n",
    "    cities.append(city)\n",
    "    \n",
    "    print(confusion_matrix(predicted_labels, true_labels))\n",
    "    print(classification_report(predicted_labels, true_labels))\n",
    "    \n",
    "    if count == 5:\n",
    "        break\n",
    "        \n",
    "list1 = cities\n",
    "list2 = pred_avg_stars\n",
    "list3 = actual_avg_stars\n",
    "\n",
    "#visualize predicted and actual average stars for 5 cities \n",
    "fig,ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "x = list1\n",
    "xn = range(len(x))\n",
    "plt.xticks(xn, list1)\n",
    "ax1.plot(xn, list2, 'g-')\n",
    "ax2.plot(xn, list3, 'r-')\n",
    "\n",
    "ax1.set_xlabel('Cities')\n",
    "ax1.set_ylabel('Predicted Avg Stars', color='g')\n",
    "ax2.set_ylabel('Actual Avg Stars', color='r') \n",
    "\n",
    "print(\"Prediction Visualization Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
